{% extends "layout.html" %}

{% block content %}
    <h2>Api</h2>

    <p>We offer a GRPC based Api. You can generate your client for your preferred language using the generators provided.</p>
    <p>The public API endpoint can be reached here: <code>challenge.msrg.in.tum.de:5023</code> </p>
    <p>You can download the protos to generate the client here: <a href="/static/challenger.proto">Proto</a></p>
    <p>See <a href="https://grpc.io/">grpc.io</a> for documentation and tutorials.</p>

    <h2>Usage</h2>
    <p>The illustration below shows the API interactions. Next we give more details to the steps and examples in Python code.</p>
    <img src="/static/img/debs.png" class="img-fluid" alt="Api usage">
    <p>You can download the example code shown below here: <a href="/static/example.py">example.py</a></p>

    <h4>Step 0</h4>
    <p>Generate the client code, as example, we use Python. For other languages check the documentation</p>

    <pre>
    <code>
pip install grpcio
python -m grpc_tools.protoc -I . --python_out=. --grpc_python_out=. challenger.proto
    </code>
    </pre>

    <h4>Step 1</h4>
    <p>First, get the location data. This returns a message which contains a list of locations. The message is bigger then what the default configuration allows. Hence increase the max_receive_message_length.</p>
    <pre>
        <code>
import challenger_pb2 as ch
import challenger_pb2_grpc as api

op = [('grpc.max_send_message_length', 10 * 1024 * 1024),
      ('grpc.max_receive_message_length', 100 * 1024 * 1024)]
with grpc.insecure_channel('challenge.msrg.in.tum.de:5023', options=op) as channel:
    stub = api.ChallengerStub(channel)
    loc = stub.getLocations(empty_pb2.Empty()) #get all the locations
        </code>
    </pre>

    <h4>Step 2</h4>
    <p>Create a new Benchmark. You have to give it your token (see profile), set a benchmark name (this is used for your personal statistics) and the batchsize.
        The event rate is around 4000 messages/second. For the final evaluation you will get access to VMs in our datacenter and bandwidth shouldn't be the bottleneck.</p>
    <pre>
        <code>
benchmarkconfiguration = ch.BenchmarkConfiguration(token="checkyourprofile",
                                                   batch_size=5000,
                                                   benchmark_name="shows_up_in_dashboard")
bench = stub.createNewBenchmark(benchmarkconfiguration)
        </code>
    </pre>

    <h4>Step 3 (optional)</h4>
    <p>Depending on your connectivity you might experience different latency and throughput. Optionally, we try to account for this by first measuring it.
        The payload of a Ping corresponds roughly to the payload of a batch and the returning Pong roughly the payload of a Result
        This kind of measurement is just for development and experimentation (since, well, it could be easily cheated ;-)).
        We do not consider that once you deploy your implementation on the VMs in our infrastructure.</p>
    <pre>
        <code>
ping = stub.initializeLatencyMeasuring(benchmark)
for i in range(10):
    ping = stub.measure(ping)
stub.endMeasurement(ping)
        </code>
    </pre>

    <h4>Step 4</h4>
    <p>First start the Benchmark. This sets the timstamp server side for the throughput measurments. Then process all the batches. The batches are correlated for the latency measurements.</p>
    <p>Once you called the endBenchmark RPC, we calculate the results.</p>

    <pre>
        <code>
stub.startBenchmark(benchmark)

batch = stub.nextMessage(benchmark)
while batch:
    result_payload = processTheBatch(batch) #here belongs your sophisticated implementation
    result = ch.Result(benchmark_id=benchmark.id, #The id of the benchmark
                       payload_seq_id=batch.seq_id,
                       result=result_payload)

    stub.processed(result) #send the result
    if batch.last:
        break

    batch = stub.nextMessage(benchmark)

stub.endBenchmark(benchmark)
        </code>
    </pre>

    <p>Still have questions/Errors/Problems? => christoph.doblander@in.tum.de</p>

{% endblock %}